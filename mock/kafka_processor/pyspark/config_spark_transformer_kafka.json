{
  "aws_region": "us-east-1",
  "environment": "dev",
  "logger_name": "utility_kafka_pyspark_security_log_processor_logger",
  "processor_typ": "utility_kafka_pyspark_security_log_processor_processor",
  "input": {
    "reader_typ": "message_broker_kafka",
    "format": "json",
    "secret_name": "dev/cs_ise/kafka",
    "format_options": {
      "kafka.bootstrap.servers": "b-1.tls.mskclusterdev.soxbku.c16.kafka.us-east-1.amazonaws.com:14001",
      "kafka.security.protocol": "SSL",
      "subscribe": "context-service-dev-utility-raw-feed",
      "kafka.ssl.keystore.location": "/var/.jks/cs-ise-transformer.keystore.jks",
      "kafka.ssl.keystore.password": "CS_KAFKA_KEYSTORE_PSSWD",
      "kafka.ssl.truststore.location": "/var/.jks/cs-ise-transformer.truststore.jks",
      "kafka.ssl.truststore.password": "CS_KAFKA_TRUSTSTORE_PSSWD",
      "kafka.ssl.key.password": "CS_KAFKA_SSL_KEY_PSSWD",
      "startingOffsets": "latest",
      "failOnDataLoss": "false"
    },
    "schema": {
      "type": "struct",
      "fields": [
        {
          "name": "timestamp",
          "type": "string",
          "nullable": true,
          "metadata": {}
        },
        {
          "name": "src_ip",
          "type": "string",
          "nullable": true,
          "metadata": {}
        },
        {
          "name": "dest_ip",
          "type": "string",
          "nullable": true,
          "metadata": {}
        },
        {
          "name": "action",
          "type": "string",
          "nullable": true,
          "metadata": {}
        },
        {
          "name": "protocol",
          "type": "string",
          "nullable": true,
          "metadata": {}
        },
        {
          "name": "bytes",
          "type": "string",
          "nullable": true,
          "metadata": {}
        }
      ]
    }
  },
  "transform": {
    "input": "raw_input",
    "conversion": [
      {
        "transform_typ": "pyspark",
        "transform_seq": "1",
        "transform_name": "1_cleanse_normalise_log_events",
        "transform_input": {
          "config_input_table_1": "raw_input"
        },
        "transform_output": {
          "config_output_table": "cleansed_normalised_output"
        },
        "transform_query": "/Volumes/cspe_context_service_dev/ise_context/data_processor/configs/1_cleanse_normalise_log_events.py"
      },
      {
        "transform_typ": "pyspark",
        "transform_seq": "2",
        "transform_name": "2_transform_log_events",
        "transform_input": {
          "config_input_table_1": "cleansed_normalised_output"
        },
        "transform_output": {
          "config_output_table": "final_transformed_output"
        },
        "transform_query": "/Volumes/cspe_context_service_dev/ise_context/data_processor/configs/2_transform_log_events.py"
      }
    ],
    "output": "final_output"
  },
  "output": {
    "writer_typ": "message_broker_kafka",
    "secret_name": "dev/cs_ise/kafka",
    "outputMode": "append",
    "stream_options": {
      "checkpointLocation": "/Volumes/cspe_context_service_dev/ise_context/data_processor/checkpoint/"
    },
    "writer_typ_options": {
      "kafka.bootstrap.servers": "b-1.tls.mskclusterdev.soxbku.c16.kafka.us-east-1.amazonaws.com:14001",
      "kafka.security.protocol": "SSL",
      "topic": "context-service-dev-utility-output-feed",
      "kafka.ssl.keystore.location": "/var/.jks/cs-ise-transformer.keystore.jks",
      "kafka.ssl.keystore.password": "CS_KAFKA_KEYSTORE_PSSWD",
      "kafka.ssl.truststore.location": "/var/.jks/cs-ise-transformer.truststore.jks",
      "kafka.ssl.truststore.password": "CS_KAFKA_TRUSTSTORE_PSSWD",
      "kafka.ssl.key.password": "CS_KAFKA_SSL_KEY_PSSWD",
      "startingOffsets": "latest"
    }
  },
  "metric" : {
    "namespace": "utility_kafka_pyspark_security_log_processor",
    "metric_set": {
      "microbatch_time": {
        "typ": "gauge",
        "custom_metric_name": "metric_microbatch_total_time"
      },
      "microbatch_transformation_time": {
        "typ": "gauge",
        "custom_metric_name": "metric_microbatch_transformation_time"
      },
      "microbatch_writer_time": {
        "typ": "gauge",
        "custom_metric_name": "metric_microbatch_writer_time"
      },
      "microbatch_writer_record_count": {
        "typ": "gauge",
        "custom_metric_name": "metric_microbatch_write_record_count"
      },
      "microbatch_record_count": {
        "typ": "counter",
        "custom_metric_name": "metric_microbatch_total_record_count"
      }
    },
    "flush_interval": 30,
    "flush_batch_size": 50
  }
}
